% Script generated by Neural Pattern Recognition app 
% This script assumes these variables are defined: % 

% x - input data. % t - target data. 
% 
[x,t]=cancer_dataset;
x = x; 
t = t;

trainFcn = 'trainscg'; 
% Scaled conjugate gradient backpropagation. 

% Create a Pattern Recognition Network  
%for hidden= [2,8,32] 
for hidden= [2, 8, 32]
    final_train_eror_mean=[]; 
    final_test_eror_mean=[]; 
    final_sd_train=[]; 
    final_sd_test=[]; 
    final_train_loss=[]; 
    hiddenLayerSize = hidden; 
    
    net2 = patternnet(hiddenLayerSize, trainFcn); 
    
    %for epoches= [ 1, 2, 4, 8, 16, 32,64] 
    for epoches= [ 1, 2, 4, 8, 16, 32, 64 ]
        % Setup Division of Data for Training, Validation, Testing
        %net.divideParam.trainRatio = 50/100; 
        %net.divideParam.valRatio = 0/100; 
        %net.divideParam.testRatio = 50/100; 
        
        ls_train=[]; 
        ls_test=[];      
        train_loss=[]; 
        
        for iters=1:30 
            net=net2; 
            net.trainParam.epochs=epoches; 
            net.trainParam.lr = 0.01; 
            random=randperm(length(x)); 
            xtrain=x(1:9,random(1:round(length(x)*0.5))); 
            ytrain=t(1:2,random(1:round(length(x)*0.5))); 
            xtest=x(1:9,random(round(length(x)*0.5:end))); 
            ytest=t(1:2,random(round(length(x)*0.5:end))); 
            
            % Train the Network 
            [net,tr] = train(net,xtrain,ytrain); 
            
            % Test the Network 
            y = net(xtest); 
            y1=net(xtrain); 
            e = gsubtract(ytest,y); 
            e1 = gsubtract(ytrain,y1); 
            performance = perform(net,ytest,y); 
            performance1 = perform(net,ytrain,y1); 
            tind = vec2ind(ytest); 
            yind = vec2ind(y); 
            tind1 = vec2ind(ytrain); 
            yind1 = vec2ind(y1); 
            percentErrors = sum(tind ~= yind)/numel(tind); 
            percentErrors1 = sum(tind1 ~= yind1)/numel(tind1); 
            
            %accuracy = sum(y == ytest)/numel(ytest) 
            %accuracy1 = sum(y1 == ytrain)/numel(ytrain) 
            % 
            ls_train=[ls_train,(percentErrors1)]; 
            ls_test=[ls_test,(percentErrors)]; 
            train_loss=[train_loss,performance1]; 
            
            %l=loss(net,xtrain,y1) 
            % View the Network %
            
            %view(net) 
        end 
        
        final_train_eror_mean=[final_train_eror_mean,mean(ls_train)]
        final_test_eror_mean=[final_test_eror_mean,mean(ls_test)]
        final_sd_train=[final_sd_train,std(ls_train)] 
        final_sd_test=[final_sd_test,std(ls_test)] 
        final_train_loss=[final_train_loss,mean(train_loss)]
        
        %length(ls_train) 
        clear ls_train; 
        clear ls_test; 
        clear train_loss; 
    end 
    
 subplot(3,1,1),
 %plot([1,2,4,8,16,32,64],final_train_eror_mean) 
 plot([1],final_train_eror_mean)
 title('Train error for hidden layer: ', hidden) 
 xlabel("No of epoches") 
 ylabel("classification error") 
 subplot(3,1,2), 
 %plot([1,2,4,8,16,32,64],final_test_eror_mean) 
 plot([1],final_test_eror_mean) 
 title('Test error for hidden layer: ', hidden) 
 xlabel("No of epoches") 
 ylabel("classification error") 
 subplot(3,1,3),
 %plot([1,2,4,8,16,32,64],final_train_loss) 
 plot([1],final_train_loss)
 title('Train loss: ', hidden) 
 xlabel("No of epoches") 
 ylabel("loss") 
 final_train_eror_mean; 
 final_test_eror_mean; 
 clear final_train_eror_mean; 
 clear final_test_eror_mean; 
end 
%view(net)